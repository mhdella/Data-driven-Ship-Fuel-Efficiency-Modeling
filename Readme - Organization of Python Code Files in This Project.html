<html><head><style>body {
   color: black;
}
</style></head><body><h1 id="acknowledgement-">Acknowledgement.</h1>
<p>This is the software infrastructure of <strong><em>the IAMU (International Association of Maritime Universities) research project titled “Data fusion and machine learning for ship fuel efficiency analysis: a small but essential step towards green shipping through data analytics” (Research Project No. 20210205_AMC). The materials and data in this project have been obtained through the support of IAMU and The Nippon Foundation in Japan.</em></strong> This project has the following investigators: Yuquan (Bill) Du (Coordinator, Lead Applicant), Peggy Shu-Ling Chen, Nataliya Nikolova, Prashant Bhaskar, and Jiangang Fei from University of Tasmania (UTAS); Alessandro Schönborn from World Maritime University (WMU) as WMU-side Chief Investigator; and Zhuo Sun from Dalian Maritime University (DMU) as DMU-side Chief Investigator. Dr Xiaohe Li laid a good Python code fundation during his University Associate role at UTAS and conducted some preliminary experiments. Ms Yanyu Chen is the main Research Assistant of this project who has major contributions to Python code and conducting experiments under the supervision of Dr Yuquan (Bill) Du. Mr Jean-Louis Bertholier developed the Python code of collecting meteorological data for ships during his Assistant Engineer internship at World Maritime University. Warm help are received from ECMWF (Centre for Medium-range Weather Forecasts) and Copernicus Marine Service (CMEMS) when we wanted to automate the download process of meteorological data. This study has been conducted using E.U. Copernicus Marine Service Information; <a href="https://doi.org/10.48670/moi-00050">https://doi.org/10.48670/moi-00050</a>. Hersbach et al. (2018) was downloaded from the Copernicus Climate Change Service (C3S) Climate Data Store. The results of this study and trained machine learning models published contain modified Copernicus Climate Change Service information 2020. Neither the European Commission nor ECMWF is responsible for any use that may be made of the Copernicus information or data it contains.</p>
<p>The following three papers explain the research work behind the Python code to be described. <strong>Cite the following papers if you use the code and trained models in this project</strong>. For an instruction on how to obtain the trained machine learning models in the following three papers and use them to estimate/forecast a mega containership&#39;s daily bunker fuel consumption, see &quot;<strong><em>Instructions on How to Use Trained Machine Learning Models.ipynb</em></strong>&quot; for details - this &quot;.ipynb&quot; file should be downloaded and run in Jupyter Notebook.</p>
<p><em>Xiaohe Li, Yuquan Du, Yanyu Chen, Son Nguyen, Wei Zhang, Alessandro Schönborn, Zhuo Sun, 2022. &quot;Data fusion and machine learning for ship fuel efficiency modeling: Part I – voyage report data and meteorological data&quot;. Communications in Transportation Research, 2, 100074.</em></p>
<p><em>Yuquan Du, Yanyu Chen, Xiaohe Li, Alessandro Schönborn, Zhuo Sun, 2022a. &quot;Data fusion and machine learning for ship fuel efficiency modeling: Part II – voyage report data, AIS data and meteorological data&quot;. Communications in Transportation Research, 2, 100073.</em></p>
<p><em>Yuquan Du, Xiaohe Li, Yanyu Chen, Alessandro Schönborn, Zhuo Sun, 2022b. &quot;Data fusion and machine learning for ship fuel efficiency modeling: Part III – sensor data and meteorological data&quot;. Communications in Transportation Research, 2, 100072.</em></p>
<p><strong>References</strong></p>
<p>Hersbach, H., Bell, B., Berrisford, P., Biavati, G., Horányi, A., Muñoz Sabater, J., Nicolas, J., Peubey, C., Radu, R., Rozum, I., Schepers, D., Simmons, A., Soci, C., Dee, D., Thépaut, J-N. (2018): ERA5 hourly data on single levels from 1979 to present. Copernicus Climate Change Service (C3S) Climate Data Store (CDS). (Accessed on 10-Sep-2021), 10.24381/cds.adbb2d47.</p>
<p>============================================================================================================================================</p>
<p>Our Python code in this project is explained as follows. There are four stages in conducting ship fuel efficiency experiments, including data dowload, data processing, data fusion, and model training and testing.</p>
<ol>
<li><p><strong><em>Data Download</em></strong> (in folder &quot;data_download&quot;) 
 Two different meteorological datasets need to be dowloaded.</p>
<p> 1.1. &quot;ear5_weather_information_download.py&quot; downloads the data of wind, waves, and sea water temperature from ECMWF (Centre for Medium-range Weather Forecasts) (Hersbach et al., 2018).</p>
<p> 1.2. &quot;copernicus_marine_ocean_wave_data_download.py&quot; downloads the data of sea currents from Copernicus Marine Service (CMEMS, also a.k.a. “Copernicus”). This file was provided by XXX from XXXX. Yanyu Chen from ... and Jean-Louis Bertholier from World Maritime Unviersity revised the code according to data requirements of the above papers. The author of this Python file is &quot;Copernicus Marine User Support Team&quot;. We obtained the permission from &quot;Copernicus Marine User Support Team&quot; to include this file to our GitHub project, with proper citation and acknowledgement.  </p>
</li>
<li><p><strong><em>Data Processing</em></strong> (in folder &quot;data_processing&quot;)
 Four different datasets need to be processed, including meterological data, voyage report data, AIS data and sensor data.</p>
<p> 2.1 <strong>Meteorological Data</strong>. Run the following Python files in order in the folder &quot;data_processing\Meteorological data&quot;.</p>
<pre><code> · <span class="hljs-string">"ocean_current_nc.py"</span> retrieves information <span class="hljs-keyword">of</span> sea currents <span class="hljs-built_in">from</span> &lt;b&gt;downloaded&lt;/b&gt; Copernicus data stored <span class="hljs-keyword">in</span> <span class="hljs-built_in">files</span> (<span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span>  data structure <span class="hljs-keyword">of</span> Rubric), according <span class="hljs-built_in">to</span> <span class="hljs-keyword">the</span> input &lt;timestamp, latitude, longitude&gt;.

 · <span class="hljs-string">"ocean_wave_hour.py"</span> retrieves information <span class="hljs-keyword">of</span> wind, waves, <span class="hljs-keyword">and</span> sea water temperature <span class="hljs-built_in">from</span> downloaded ECMWF data stored <span class="hljs-keyword">in</span> <span class="hljs-built_in">files</span> (<span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span>  data structure <span class="hljs-keyword">of</span> Rubric), according <span class="hljs-built_in">to</span> <span class="hljs-keyword">the</span> input &lt;timestamp, latitude, longitude&gt;.

 · <span class="hljs-string">"ocean_import_nan.py"</span> converts <span class="hljs-string">"nan"</span> values <span class="hljs-keyword">of</span> data (outputs <span class="hljs-keyword">of</span> <span class="hljs-string">"ocean_current_nc.py"</span> <span class="hljs-keyword">and</span> <span class="hljs-string">"ocean_wave_hour.py"</span>) <span class="hljs-built_in">to</span> <span class="hljs-string">"NaN"</span> <span class="hljs-keyword">for</span> <span class="hljs-keyword">the</span> convience <span class="hljs-keyword">of</span> further data cleaning. Run this <span class="hljs-built_in">file</span> twice: once <span class="hljs-keyword">for</span> <span class="hljs-keyword">the</span> data output <span class="hljs-keyword">of</span> <span class="hljs-string">"ocean_current_nc.py"</span>; once <span class="hljs-keyword">for</span> <span class="hljs-keyword">the</span> data output <span class="hljs-keyword">of</span> <span class="hljs-string">"ocean_wave_hour.py"</span>. 

 · <span class="hljs-string">"combine_ow_oc.py"</span> combines Copernicus data (<span class="hljs-keyword">after</span> running <span class="hljs-keyword">of</span> <span class="hljs-string">"ocean_import_nan.py"</span>) <span class="hljs-keyword">and</span> ECMWF data (<span class="hljs-keyword">after</span> running <span class="hljs-keyword">of</span> <span class="hljs-string">"ocean_import_nan.py"</span>), <span class="hljs-keyword">and</span> cleans <span class="hljs-keyword">the</span> errors <span class="hljs-keyword">and</span> noises.
</code></pre><p> 2.2 <strong>Voyage Report Data</strong>. Run the following Python files in order in the folder &quot;data_processing\Voyage report&quot;.</p>
<pre><code> · <span class="hljs-string">"report_process_correct.py"</span> <span class="hljs-keyword">and</span> <span class="hljs-string">"report_process_checklist.py"</span> are used <span class="hljs-built_in">to</span> clean voyage report data. Note than different shipping companies use different data structures <span class="hljs-keyword">for</span> voyage reports, <span class="hljs-keyword">and</span> these code here might <span class="hljs-keyword">not</span> be able <span class="hljs-built_in">to</span> be directly used <span class="hljs-built_in">to</span> clean <span class="hljs-keyword">the</span> errors <span class="hljs-keyword">or</span> noises <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> voyage report you obtained <span class="hljs-built_in">from</span> <span class="hljs-keyword">a</span> shipping company.

 · <span class="hljs-string">"report_process_divid.py"</span> claculates <span class="hljs-keyword">the</span> hourly geographical positions <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> ship: &lt;timestamp, latitude, longitude&gt;, according <span class="hljs-built_in">to</span> Great Circle Route (rhumb <span class="hljs-built_in">line</span>).

 · <span class="hljs-string">"report_cube.py"</span> generates <span class="hljs-keyword">a</span> data cube/container/rubric (<span class="hljs-built_in">file</span>) that <span class="hljs-keyword">contains</span> <span class="hljs-keyword">the</span> hourly &lt;timestamp, latitude, longitude&gt; information obtained <span class="hljs-built_in">from</span> <span class="hljs-string">"report_process_divid.py"</span>, <span class="hljs-keyword">and</span> <span class="hljs-keyword">the</span> columns names <span class="hljs-keyword">for</span> machine learning features/variables (speed, displacement, wind direction, wind waves, swell,....), though <span class="hljs-keyword">the</span> data <span class="hljs-keyword">for</span> these variables/features are <span class="hljs-keyword">not</span> populated <span class="hljs-keyword">in</span> yet.

 · <span class="hljs-string">"report_cube_modification.py"</span> rounds <span class="hljs-keyword">the</span> longitute values <span class="hljs-keyword">of</span> e.g. <span class="hljs-number">180.05</span> degree <span class="hljs-built_in">to</span> <span class="hljs-number">179.9</span> degree, <span class="hljs-keyword">or</span> rounds <span class="hljs-keyword">the</span> longitute values <span class="hljs-keyword">of</span> e.g. <span class="hljs-number">-180.05</span> degree <span class="hljs-built_in">to</span> <span class="hljs-number">-179.9</span> degree, because downloaded meteorological data uses <span class="hljs-keyword">the</span> longitude range [<span class="hljs-number">-179.975</span> degree, <span class="hljs-number">179.975</span> degree].
</code></pre><p> 2.3 <strong>AIS Data</strong>. Run the following Python files in order in the folder &quot;data_processing\AIS data&quot;.</p>
<pre><code> · <span class="hljs-string">"ais_cube_checklist.py"</span> samples hourly data entries <span class="hljs-keyword">from</span> raw AIS data because only hourly information <span class="hljs-keyword">of</span> &lt;timestamp, latitude, longitude, heading&gt; <span class="hljs-keyword">is</span> needed. In a rare situation <span class="hljs-keyword">where</span> a <span class="hljs-built_in">time</span> period (<span class="hljs-built_in">say</span> <span class="hljs-number">4</span> continous hours) doesn't have any AIS data entries, hourly timestamps are inserted. 

 · <span class="hljs-string">"ais_report_combine.py"</span> corrects <span class="hljs-keyword">the</span> <span class="hljs-string">"heading"</span> information <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> sampled AIS data entries: when <span class="hljs-string">"heading"</span> information <span class="hljs-keyword">is</span> absent <span class="hljs-keyword">from</span> AIS data, <span class="hljs-string">"true course"</span> <span class="hljs-keyword">in</span> AIS data will be used; <span class="hljs-keyword">if</span> <span class="hljs-string">"true course"</span> <span class="hljs-keyword">is</span> also absent <span class="hljs-keyword">from</span> AIS data, <span class="hljs-string">"true course"</span> informaiton <span class="hljs-keyword">from</span> voyage report <span class="hljs-keyword">is</span> used.

 · <span class="hljs-string">"ais_cube_divid_correct.py"</span> generates hourly geographical postions <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> ship <span class="hljs-keyword">for</span> <span class="hljs-keyword">the</span> rare situation <span class="hljs-keyword">in</span> <span class="hljs-string">"ais_cube_checklist.py"</span> <span class="hljs-keyword">where</span> a <span class="hljs-built_in">time</span> period (<span class="hljs-built_in">say</span> <span class="hljs-number">4</span> continous hours) doesn't have any AIS data entries.

 · <span class="hljs-string">"ais_cube_match.py"</span> generates a data cube/container/rubric (<span class="hljs-built_in">file</span>) <span class="hljs-keyword">that</span> <span class="hljs-keyword">contains</span> <span class="hljs-keyword">the</span> hourly &lt;timestamp, latitude, longitude&gt; information obtained <span class="hljs-keyword">from</span> <span class="hljs-string">"ais_cube_divid_correct.py"</span>, <span class="hljs-keyword">and</span> <span class="hljs-keyword">the</span> columns names <span class="hljs-keyword">for</span> machine learning features/variables (speed, displacement, wind direction, wind waves, swell,....), though <span class="hljs-keyword">the</span> data <span class="hljs-keyword">for</span> these variables/features are <span class="hljs-keyword">not</span> populated <span class="hljs-keyword">in</span> yet.
</code></pre><p> 2.4 <strong>Sensor Data</strong>. Run the following Python files in order in the folder &quot;data_processing\Sensor data&quot;.</p>
<pre><code> · <span class="hljs-string">"sensor_cube_selection.py"</span> cleans sensor <span class="hljs-class"><span class="hljs-keyword">data</span>.</span>
</code></pre></li>
<li><p><strong><em>Data Fusion</em></strong> (in folder &quot;data_fusion&quot;)
 Data fusion apporaches used in three papers.</p>
<p> 3.1 <strong>Data fusion solution 1 (Li et al., 2022)</strong> - fusion of voyage report data and meteorological data. Run the following Python files in order in the folder &quot;data_fusion\Voyage data fusion&quot;.</p>
<pre><code> · <span class="hljs-string">"voyage_weather_combination.py"</span> fuses voyage report data <span class="hljs-built_in">and</span> meteorological data, <span class="hljs-built_in">and</span> make necessary calculations about <span class="hljs-built_in">wind</span>, <span class="hljs-built_in">waves</span> <span class="hljs-built_in">and</span> current directions.

 · <span class="hljs-string">"voyage_weather_combinatioant_transfer.py"</span> converts the precise values of <span class="hljs-built_in">wind</span> <span class="hljs-built_in">speed</span>, <span class="hljs-built_in">wind</span> directions, wave directions, <span class="hljs-built_in">and</span> sea currents directions <span class="hljs-keyword">to</span> fuzzy values. See Li et al. (<span class="hljs-number">2022</span>).  
</code></pre><p> 3.2 <strong>Data fusion solution 2 (Du et al., 2022a)</strong> - fusion of voyage report data, AIS data, and meteorological data. Run the following Python files in order in the folder &quot;data_fusion\AIS data fusion&quot;.</p>
<pre><code> · <span class="hljs-string">"ais_weather_combination.py"</span> fuses voyage report data, AIS data, <span class="hljs-built_in">and</span> meteorological data, <span class="hljs-built_in">and</span> make necessary calculations about <span class="hljs-built_in">wind</span>, <span class="hljs-built_in">waves</span> <span class="hljs-built_in">and</span> current directions.

 · <span class="hljs-string">"ais_weather_combination_transfer.py"</span> converts the precise values of <span class="hljs-built_in">wind</span> <span class="hljs-built_in">speed</span>, <span class="hljs-built_in">wind</span> directions, wave directions, <span class="hljs-built_in">and</span> sea currents directions <span class="hljs-keyword">to</span> fuzzy values. See Li et al. (<span class="hljs-number">2022</span>).  
</code></pre><p> 3.3 <strong>Data fusion solution 3 (Du et al., 2022b)</strong> - fusion of sensor data and meteorological data. Run the following Python files in order in the folder &quot;data_fusion\Sensor data fusion&quot;.</p>
<pre><code> · <span class="hljs-string">"sensor_weather_combination.py"</span> fuses sensor <span class="hljs-meta">data</span> <span class="hljs-keyword">and </span>meteorological <span class="hljs-meta">data</span>, <span class="hljs-keyword">and </span>make necessary calculations about wind, waves <span class="hljs-keyword">and </span>current directions.
</code></pre></li>
</ol>
<ol>
<li><p><strong>Hyperparameter optimization/selection</strong> (in folder &quot;parameter_selection&quot;)</p>
<p> · &quot;ET_H.py&quot; in the folder &quot;parameter_selection\ET_Set3Precise&quot;: Given the best dataset <em>Set3Precise</em> found in Li et al. (2022) (Readers can use &quot;data_sample\Set3Precise.xlsx&quot; for experiments, but keep in mind that this is a fake dataset we randomely generated), this python file is used to optimize the hyperparameters of extremely randomized trees (ET) model.</p>
<p> · &quot;GB_H.py&quot; in the folder &quot;parameter_selection\GB_AIS5Precise&quot;: Given the best dataset <em>AIS5Precise</em> found in Du et al. (2022a) (Readers can use &quot;data_sample\AIS5Precise.xlsx&quot; for experiments, but keep in mind that this is a fake dataset we randomely generated), this python file is used to optimize the hyperparameters of gradient tree boosting (GB) model.</p>
<p> · &quot;XG_H.py&quot; in the folder &quot;parameter_selection\XG_Sensor2&quot;: Given the best dataset <em>Sensor2</em> found in Du et al. (2022b) (Readers can use &quot;data_sample\Sensor2.xlsx&quot; for experiments, but keep in mind that this is a fake dataset we randomely generated), this python file is used to optimize the hyperparameters of XGBoost (XG) model. </p>
</li>
<li><p><strong>Model Training and Test</strong> (in folder &quot;model_training&quot;)</p>
<p> After hyperparameter optimization/selection, documents/files that contain the optimized hyperparameter values will be generated. According to these parameter documents/files, run the following code to train and test machine learning models. For instance, </p>
<p> · &quot;ET_Cycle_H.py&quot; in the folder &quot;model_training\ET_Set3Precise&quot;: train and test extremely randomized trees (ET) model given the best dataset <em>Set3Precise</em> (Readers can use &quot;data_sample\Set3Precise.xlsx&quot; for experiments, but keep in mind that this is a fake dataset we randomely generated), as discussed in Li et al. (2022).</p>
<p> · &quot;GB_Cycle_H.py&quot; in the folder &quot;model_training\GB_AIS5Precise&quot;: train and test gradient tree boosting (GB) model given the best dataset <em>AIS5Precise</em> (Readers can use &quot;data_sample\AIS5Precise.xlsx&quot; for experiments, but keep in mind that this is a fake dataset we randomely generated), as discussed in Du et al. (2022a).</p>
<p> · &quot;XG_Cycle_H.py&quot; in the folder &quot;model_training\XG_Sensor2&quot;: train and test XGBoost (XG) model given the best dataset <em>Sensor2</em> (Readers can use &quot;data_sample\Sensor2.xlsx&quot; for experiments, but keep in mind that this is a fake dataset we randomely generated), as discussed in Du et al. (2022b).</p>
</li>
</ol>
</body></html>
